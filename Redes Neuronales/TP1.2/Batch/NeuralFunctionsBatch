function guess = makeGuessWithMatrix(input)
	global weights
	global rawOutputs
	global outputs
	global layersCount

	membraines = zeros(1, columns(input))-1;
	% Caculate the output of the first layer
	rawOutputs{1} = weights{1}*[membraines; input];
	outputs{1} = activate(rawOutputs{1});

	% Caculate the output of each layer
	for i=2:layersCount
		% Wigths of the current layer times last output with a -1 at the beggining
		rawOutputs{i} = weights{i}*[membraines; outputs{i-1}];
		outputs{i} = activate(rawOutputs{i});
	endfor
	
	guess = outputs{end};
endfunction

function guess = makeGuess(input)
	global weights
	global rawOutputs
	global outputs
	global layersCount

	% Caculate the output of the first layer
	rawOutputs{1} = weights{1}*[-1; input];
	outputs{1} = activate(rawOutputs{1});
	
	% Caculate the output of each layer
	for i=2:layersCount
		% Wigths of the current layer times last output with a -1 at the beggining
		rawOutputs{i} = weights{i}*[-1; outputs{i-1}];
		outputs{i} = activate(rawOutputs{i});
	endfor

	guess = outputs{end};
endfunction

function error = medianBatchError()
	guess = makeGuessWithMatrix(getSampleMatrix());
	error = sum((getAnswerMatrix()-guess).**2)/(2*getSampleSize());
endfunction

function error = medianTestingError()
	global testingSize
	global testingMatrix
	global testingAnswerMatrix

	guess = makeGuessWithMatrix(testingMatrix);
	error = sum((testingAnswerMatrix-guess).**2)/(2*testingSize);
endfunction

function error = medianTrainingError()
	global trainingIndexes

	n=length(trainingIndexes);
	trainError=[];
	for i = trainingIndexes
		input=getSample(i);
		answer=getAnswer(i);
		guess= makeGuess(input);
		trainError=[trainError,(answer-guess)**2];
	endfor
	error=sum(trainError)/(2*n);
endfunction


function adaptEta()
	global errors
	global consecutiveErrorReduction

	lastError = medianTrainingError()
	errors = [errors, lastError];

	if(length(errors)>1)
		if(errors(end)<lastError)
			consecutiveErrorReduction +=1;

			if(consecutiveErrorReduction==maxEtaErrorReductions)
				consecutiveErrorReduction=0;
				learningRate+= etaPositiveAdjustment;
			endif

		elseif(errors(end)>lastError)
			consecutiveErrorReduction=0;
			learningRate-= etaNegativeAdjustment * learningRate;
		endif
	endif
	
endfunction