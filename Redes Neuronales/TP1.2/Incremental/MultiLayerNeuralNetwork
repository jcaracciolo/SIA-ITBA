source('Incremental/NeuralFunctions')
% inputSize: Size of each input
% outputSize: Size of the output
% layersSize: Size of each layer
% learningRate: Rate of learning

% Trainer functions
% trainerPath: Path to trainer file
%  -- ? getSampleSize()
%  -- ? getSample(int index)
%  -- ? getAnswer(int index)
source(trainerPath)


% Create array with all sizes
layersSize = [layersSize, outputSize];
global layersCount = length(layersSize);

% Setup RNG
if (exist('randomSeed', 'var') == 1)
    rand('seed',randomSeed)
else
	seed = rand('seed')
	save randState seed
	rand('seed', seed)
endif


%create initial random matrix
global weights = cell(layersCount, 1);
global deltaWeights = cell(layersCount, 1);
global deltas = cell(layersCount,1);

% Initial weights takes into account inputSize
weights(1) = rand(layersSize(1), inputSize+1);
deltaWeights(1) = zeros(layersSize(1), inputSize+1);

for i=2:layersCount
	% Matrix size is layer(i+1) X (layer(i)+1)
	weights(i) = rand(layersSize(i), layersSize(i-1)+1);
	deltaWeights(i) = zeros(layersSize(i), layersSize(i-1)+1);
endfor

global lastWeights = weights;
global lastDeltaWeights = deltaWeights;

%Output vector for each layer
global rawOutputs = cell(layersCount,1);
global outputs = cell(layersCount,1);

sampleSize = getSampleSize();
samples = randperm(sampleSize);
trainingSize = ceil(sampleSize*trainingPercentage);
testingSize = sampleSize - trainingSize;
global trainingIndexes = samples(1:trainingSize);
global testingIndexes = samples(trainingSize+1:end);

global epochs = 1;	
global errors = [medianError()];
global trainingErrors=[medianTrainingError()];
global testingErrors=[medianTestingError()];
global lastError=errors(end);
global lastTrainingError=trainingErrors(end);
global lastTestingError=testingErrors(end);

displayCounter=0;

while(lastError>errorGoal)
	lastError
	minPlot = 1;
	if(exist('visual', 'var') == 1 && visual)
		if(length(errors) >  minPlot)
			hold on;
			mini = min([minPlot, length(errors)]);
			if(displayCounter==displayRate)
				set(gca,'Color',[0,0,0]) 
	            corrected = getCorrected(); 
	            ratio = corrected/testingSize*100; 
	            title ( 
	              sprintf('{\\fontsize{12} Errors - current LearningRate: %.3f - guessed: %d/%d (%.2f%%)}', 
	              learningRate,corrected,testingSize,ratio)); 
	            % plot(mini:length(errors),errors(mini:end),'w');  
	            plot(mini:length(testingErrors),testingErrors(mini:end),'g');  
	            plot(mini:length(trainingErrors),trainingErrors(mini:end),'r');  
	            legend( 
	              % sprintf('{\\fontsize{12} MedianError %f\n}',lastError), 
	              sprintf('{\\fontsize{12} trainingError %f\n}',lastTrainingError), 
	              sprintf('{\\fontsize{12} testingError %f\n}',lastTestingError) 
	            )      
	            refresh;  
	          displayCounter=0;  
			endif
		else
	         displayCounter=0;
		endif
	endif

	epochs +=1;
	displayCounter+=1;
	lastWeights = weights;
	lastDeltaWeights = deltaWeights;

	samplesShuffled = trainingIndexes(randperm(trainingSize));
	for index = samplesShuffled

		% Input must be a column vector with a -1 at the beggining
		input = getSample(index);
		lastOutput = makeGuess(input);
		expected = getAnswer(index);

		%Correcting
		% Calculate the last delta to start backpropagation
		deltas{end} = times(correction(rawOutputs{end}), (expected - lastOutput));

		% For each delta, calculate it by correcting the output of the given layer
		% point product by the matrix product of
		% the weigths of the upper layer (removing the threshold column) and
		% the delta of the upper layer. 
		for i=fliplr(1:layersCount-1)
			deltas{i} = times(correction(rawOutputs{i}), (weights{i+1}(:,2:end)'*deltas{i+1}));
		endfor


		deltaWeights{1} = learningRate*(deltas{1}*([-1; input]')) + alphaMomentum*deltaWeights{1};
		weights{1} += deltaWeights{1};
		for(i=2:layersCount)
			deltaWeights{i} = learningRate*(deltas{i}*([-1; outputs{i-1}]')) + alphaMomentum*deltaWeights{i};
			weights{i} += deltaWeights{i};
		endfor
	endfor

	adaptEta()

endwhile

if(exist('outputOn', 'var') == 1 && outputOn)
	save(weightsPath, "weights");
endif

testingError = 0;
correct=0;
for test = testingIndexes
	input = getSample(test);
	guess = makeGuess(input);
	expected = getAnswer(test);

	testingError += (guess - expected)**2;
	if(abs(guess - expected)<validateEpsilon)
		correct+=1;
	endif
endfor

testingError = testingError/(2*length(testingIndexes));
printf('Guessed %d out of %d. Ratio: %f wit a %f error\n',
	correct, testingSize,correct/testingSize, validateEpsilon) 
if (exist('visual', 'var') == 1 && visual)
	plot(1:length(errors),errors)  
	pause()
endif
